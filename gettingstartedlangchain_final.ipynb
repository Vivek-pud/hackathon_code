{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad567ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d715d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Instantiation\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model = \"qwen-qwq-32b\",temperature=1)\n",
    "model.invoke(\"Hi My name is vivek\") ## you can invoke it directly like this or use messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\n",
    "    (\"system\",\"you are a product designer and should be able to answer product related queries\"),\n",
    "    (\"human\",\"What is a user journey\"),\n",
    "]\n",
    "\n",
    "ai_msg = model.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt engineering || Invocation\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are an expert AI engineer. Provide me answer based on the question in JSON format\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc91136",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chaining\n",
    "chain = prompt | model \n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41feab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"can you tell me about langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STR Output Parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | model | output_parser\n",
    "response = chain.invoke({\"input\":\"can you tell me about langsmith\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e0c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa226fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### JSON Output Parser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query \\n {format_instruction} \\n {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables = {\"format_instruction\":output_parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "model=ChatGroq(model = \"gemma2-9b-it\",temperature=0)\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model|output_parser\n",
    "response = chain.invoke({\"query\":\"can you tell me about langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31e4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assignement - Return the output in either JSON or XML using Chat prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate (\n",
    "    [\n",
    "        (\"system\",\"You are an AI engineer, provide me the response in XML format\"),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "model=ChatGroq(model = \"gemma2-9b-it\",temperature=0)\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5de548",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model\n",
    "responses = chain.invoke({\"input\":\"can you tell me about elon musk\"})\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bc2a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Assignement - Return the ouptut using XML parser\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query in the following XML format:\\n{format_instruction}\\nQuery: {query}\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables = {\"format_instruction\":output_parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "model=ChatGroq(model = \"gemma2-9b-it\",temperature=0)\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5160b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model\n",
    "response = chain.invoke({\"query\":\"can you tell me about Elon musk\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ec9b13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model=ChatGroq(model = \"gemma2-9b-it\",temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f842c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why do dogs run in circles?',\n",
       " 'punchline': \"Because it's really hard to run in squares!\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model=ChatGroq(model = \"gemma2-9b-it\",temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke about dogs.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query with two key value pairs setup and punchline.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9428d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
